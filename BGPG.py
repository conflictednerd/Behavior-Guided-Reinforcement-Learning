# Policy optimization using behavior guided policy gradient

# To the advantages of each trajectory, add the WD score and compute the policy gradient
# Be careful not to normalize the reward-to-gos after adding WD scores as it's just a constant